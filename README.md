# Autonomous Robots

Lecture Notes and Experiments on Autonomous Robots

| **Topic** | **Note** | **Code** |
| :--- | :---: | :--- |
| ROS2 | [PDF](https://drive.google.com/file/d/1LaWyp9g2lKIGXSB5wsFIJdPkhkGgJtfK/view?usp=sharing) | [ROS2](ros2) |
| Navigation | [PDF](https://drive.google.com/file/d/1UzeNSkWWHATLXmAEcyfabvVfhwmRMu5V/view?usp=sharing) | - |
| Localization | [PDF](https://drive.google.com/file/d/1nyhgjG2B07__5PhBgBXe9yiMRfqCk8Bm/view?usp=sharing) | - |
| Perception | [PDF](https://drive.google.com/file/d/1tZcBpqq-5jJ2vID9ryoN6sflCSZ9sJsk/view?usp=sharing) | - |
| Visual Geometry | [PDF](https://drive.google.com/file/d/1mW31Csyx3tbVoknNvRaBG17z1x5YXhbv/view?usp=sharing) | - | 
| Kinematics | [PDF](https://drive.google.com/file/d/1BGR3RCgn05K2cvbFuy3s8DrGYGJIbtZS/view?usp=sharing) | - |


### Agents in Robotics

- [RoboGen](https://github.com/Genesis-Embodied-AI/RoboGen)
- [OpenMind](https://openmind.org/)
- [Ark Framework](https://github.com/Robotics-Ark/ark_framework)


### Memory for Robotics

- [Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering](https://arxiv.org/pdf/2507.12846)
- [NVIDIA's ReMEmbR](https://nvidia-ai-iot.github.io/remembr)
- [FindingDory](https://arxiv.org/pdf/2506.15635)

### Blogs
- [3D Perception by NVIDIA](https://developer.nvidia.com/blog/r2d2-building-ai-based-3d-robot-perception-and-mapping-with-nvidia-research/)
  
### Datasets

- [EgoDex](https://arxiv.org/pdf/2505.11709)
- [Princeton Digital Assets](https://princeton-vl.github.io/infinigen-sim/)
- [GraspGen](https://graspgen.github.io/)
- [ShareGPT-4o-Image](https://github.com/FreedomIntelligence/ShareGPT-4o-Image)
- [Wan Video Generation](https://github.com/Wan-Video/Wan2.2?tab=readme-ov-file)
- [RoboGen](https://arxiv.org/pdf/2311.01455)
- [Large Scale Grasp Dataset](https://research.nvidia.com/publication/2021-05_acronym-large-scale-grasp-dataset-based-simulation)
- [Rosario Agricultural Dataset](https://cifasis.github.io/rosariov2/)
- [Project Go-Big](https://www.figure.ai/news/project-go-big)
- [Behavior Challenge by Stanford](https://behavior.stanford.edu/index.html)
- [BridgeData V2: A Dataset for Robot Learning at Scale](https://rail-berkeley.github.io/bridgedata/)
- [Robocasa](https://robocasa.ai/) :star2:

### Foundation Models

- [Perpeption Foundation Model](https://ai.meta.com/blog/meta-fair-updates-perception-localization-reasoning/)
- [Vision Language Model Book](https://books.google.com.ph/books?hl=en&lr=&id=EnqCEQAAQBAJ&oi=fnd&pg=PA228&ots=gd6NsKrxmc&sig=xrZ7-mB00G-w_QyRlAXGEhfLNAU&redir_esc=y#v=onepage&q&f=false)
  
### Grasping

- [FoundationGrasp and GraspGPT](https://github.com/mkt1412/GraspGPT_public)

### Inference Pipeline

- [DeepStream8](https://developer.nvidia.com/blog/build-a-real-time-visual-inspection-pipeline-with-nvidia-tao-6-and-nvidia-deepstream-8/)


### Papers

- [Hierarchical Reasoning Model](https://github.com/sapientinc/HRM/)
- [Imitating Humans](https://kimhanjung.github.io/UniSkill/)


### Reinforcement Learning Framework

- [EasyR1](https://github.com/hiyouga/EasyR1)
- [R-Zero](https://github.com/Chengsong-Huang/R-Zero)
- [verl: Volcano Engine Reinforcement Learning for LLMs](https://github.com/volcengine/verl)


### SLAM

- [Handbook](http://asrl.utias.utoronto.ca/~tdb/slam/)

### Tracking

- [3D Object Tracking](https://light.princeton.edu/publication/inverse-rendering-tracking/)
- [Person Tracking (Sports)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/basketball-ai-how-to-detect-track-and-identify-basketball-players.ipynb)
  


### Vision

- [Dinov3](https://ai.meta.com/blog/dinov3-self-supervised-vision-model)
- [Map Anything](https://map-anything.github.io/)

### Vision Language Action (VLA)

- [OpenPi](https://github.com/Physical-Intelligence/openpi)

### World Models

- [NVIDIA Cosmos Reasoning](https://research.nvidia.com/labs/dir/cosmos-reason1/)
- [DreamgGem by NVIDIA](https://research.nvidia.com/labs/gear/dreamgen/)
- [Genesis RoboGen](https://github.com/Genesis-Embodied-AI/RoboGen)
- [Wan2.2](https://github.com/Wan-Video/Wan2.2)

